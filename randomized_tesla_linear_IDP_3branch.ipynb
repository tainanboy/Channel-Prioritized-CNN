{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import sampler\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "# specify dtype\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "print(torch.cuda.device_count())\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 4e-3\n",
    "momentum = 0.9\n",
    "num_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# pick 3 points from 0.1~1\n",
    "# then train these 3 IDP points randomly, with one point reach early stopping, jump to another, until totoal epoch is reached\n",
    "#total_points = list(map(lambda x: x/10, range(1,11)))\n",
    "total_points = [0.2, 0.5, 1]\n",
    "i = random.choice(range(len(total_points)))\n",
    "print(total_points[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "data_path = '/home/put_data/frank840925/IDP/data'\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_path, \n",
    "                                        train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
    "                                         num_workers=4)\n",
    "\n",
    "valset = torchvision.datasets.CIFAR10(root=data_path, \n",
    "                                       train=False, download=True, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, sampler=ChunkSampler(5000,0),\n",
    "                                       num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_path, \n",
    "                                       train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, sampler=ChunkSampler(5000,5000),\n",
    "                                        num_workers=4)\n",
    "\n",
    "print(trainset.__len__())\n",
    "print(valset.__len__())\n",
    "print(testset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Helper functions\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def plot_losses(loss_history1=None, loss_history2=None):\n",
    "    plt.clf()\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    if loss_history1:\n",
    "        ax1.plot(loss_history1, color=\"blue\", label=\"train\")\n",
    "    if loss_history2:\n",
    "        ax1.plot(loss_history2, color=\"green\", label=\"val\")\n",
    "    #ax2 = ax1.twinx()\n",
    "    #ax2.set_yscale('log')\n",
    "    plt.xlabel(\"epoch\") \n",
    "    plt.ylabel(\"loss\") \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(\"Cross-entropy loss\")\n",
    "    #plt.savefig('output_losses.png')\n",
    "\n",
    "def plot_accuracy(accuracy1=None, accuracy2=None):\n",
    "    plt.clf()\n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(111)\n",
    "    if accuracy1:\n",
    "        ax1.plot(accuracy1, color=\"red\", label=\"train\")\n",
    "    if accuracy2:\n",
    "        ax1.plot(accuracy2, color=\"black\", label=\"val\")\n",
    "    plt.xlabel(\"epoch\") \n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(\"Train/Val accuracy\") \n",
    "    #plt.savefig('accuracy.png')\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self-defined modules(layers)\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # read in N, C, H, W\n",
    "        N, C, H, W = x.size()\n",
    "        # flatten the C * H * W values into a single vector per image\n",
    "        return x.view(N, -1)  \n",
    "    \n",
    "class idp_tensor(nn.Module):\n",
    "    def __init__(self, idp):\n",
    "        super(idp_tensor, self).__init__()\n",
    "        self.idp = idp\n",
    "    def forward(self, c):\n",
    "        #input tensor c, size N*C*H*W, output with the same size, some channels zeroed according to idp\n",
    "        N, C, H, W = c.size()\n",
    "        non_zero_channel = int(C*(self.idp))\n",
    "        zero_channels = C-non_zero_channel\n",
    "        if zero_channels > 0:\n",
    "            #zeros = Variable(torch.zeros(N, zero_channels, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(zero_channels).view(zero_channels,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(zero_channels, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c = torch.cat([c[:, :non_zero_channel, :, :].clone(), zeros], 1).type(dtype)\n",
    "            #c[:, non_zero_channel:, :, :] = zeros\n",
    "            return c\n",
    "        else:\n",
    "            return c\n",
    "        \n",
    "class first_idp_tensor_3(nn.Module):\n",
    "    def __init__(self, idp1=0.35, idp2=0.7, idp3=1):\n",
    "        super(first_idp_tensor_3, self).__init__()\n",
    "        self.idp1 = idp1\n",
    "        self.idp2 = idp2\n",
    "        self.idp3 = idp3\n",
    "    def forward(self, c):\n",
    "        #input the first conv-Relu-Linear output, N*C*H*W, replicate and apply idp and concat in first dim (N)\n",
    "        N, C, H, W = c.size()\n",
    "        non_zero_channel_1 = int(C*(self.idp1))\n",
    "        non_zero_channel_2 = int(C*(self.idp2))\n",
    "        non_zero_channel_3 = int(C*(self.idp3))\n",
    "        if C-non_zero_channel_1 > 0:\n",
    "            #zeros = Variable(torch.zeros(N, C-non_zero_channel_1, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(C-non_zero_channel_1).view(C-non_zero_channel_1,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(C-non_zero_channel_1, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c1 = torch.cat([c[:, :non_zero_channel_1, :, :].clone(), zeros], 1).type(dtype)\n",
    "        else:\n",
    "            c1 = c\n",
    "        if C-non_zero_channel_2 > 0:\n",
    "            #zeros = Variable(torch.zeros(N, C-non_zero_channel_2, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(C-non_zero_channel_2).view(C-non_zero_channel_2,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(C-non_zero_channel_2, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c2 = torch.cat([c[:, :non_zero_channel_2, :, :].clone(), zeros], 1).type(dtype)\n",
    "        else:\n",
    "            c2 = c\n",
    "        if C-non_zero_channel_3 > 0:\n",
    "            #zeros = Variable(torch.zeros(N, C-non_zero_channel_3, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(C-non_zero_channel_3).view(C-non_zero_channel_3,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(C-non_zero_channel_3, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c3 = torch.cat([c[:, :non_zero_channel_3, :, :].clone(), zeros], 1).type(dtype)\n",
    "        else:\n",
    "            c3 = c\n",
    "        out = torch.cat([c1, c2, c3], 0)\n",
    "        return out\n",
    "        \n",
    "class middle_idp_tensor_3(nn.Module):\n",
    "    def __init__(self, idp1=0.35, idp2=0.7, idp3=1):\n",
    "        super(middle_idp_tensor_3, self).__init__()\n",
    "        self.idp1 = idp1\n",
    "        self.idp2 = idp2\n",
    "        self.idp3 = idp3\n",
    "    def forward(self, c):\n",
    "        #input a middle conv-Relu-Linear output, (3*N)*C*H*W, apply IDP1, IDP2, IDP3 to each\n",
    "        NN, C, H, W = c.size()\n",
    "        if NN>=3:\n",
    "            N = int(NN/3)\n",
    "            non_zero_channel_1 = int(C*(self.idp1))\n",
    "            non_zero_channel_2 = int(C*(self.idp2))\n",
    "            non_zero_channel_3 = int(C*(self.idp3))\n",
    "            c1 = c[:N,:,:,:]\n",
    "            c2 = c[N:2*N,:,:,:]\n",
    "            c3 = c[2*N:,:,:,:]\n",
    "            if C-non_zero_channel_1 > 0:\n",
    "                #zeros = Variable(torch.zeros(N, C-non_zero_channel_1, H, W)).type(dtype)\n",
    "                zeros = Variable(torch.zeros(C-non_zero_channel_1).view(C-non_zero_channel_1,1)).type(dtype) #C\n",
    "                zeros = zeros.expand(C-non_zero_channel_1, H) #C*H\n",
    "                zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "                zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "                c1 = torch.cat([c1[:, :non_zero_channel_1, :, :].clone(), zeros], 1).type(dtype)\n",
    "            else:\n",
    "                c1 = c1\n",
    "            if C-non_zero_channel_2 > 0:\n",
    "                #zeros = Variable(torch.zeros(N, C-non_zero_channel_2, H, W)).type(dtype)\n",
    "                zeros = Variable(torch.zeros(C-non_zero_channel_2).view(C-non_zero_channel_2,1)).type(dtype) #C\n",
    "                zeros = zeros.expand(C-non_zero_channel_2, H) #C*H\n",
    "                zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "                zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "                c2 = torch.cat([c2[:, :non_zero_channel_2, :, :].clone(), zeros], 1).type(dtype)\n",
    "            else:\n",
    "                c2 = c2\n",
    "            if C-non_zero_channel_3 > 0:\n",
    "                #zeros = Variable(torch.zeros(N, C-non_zero_channel_3, H, W)).type(dtype)\n",
    "                zeros = Variable(torch.zeros(C-non_zero_channel_3).view(C-non_zero_channel_3,1)).type(dtype) #C\n",
    "                zeros = zeros.expand(C-non_zero_channel_3, H) #C*H\n",
    "                zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "                zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "                c3 = torch.cat([c3[:, :non_zero_channel_3, :, :].clone(), zeros], 1).type(dtype)\n",
    "            else:\n",
    "                c3 = c3\n",
    "            out = torch.cat([c1, c2, c3],0)\n",
    "            return out\n",
    "        else:\n",
    "            return c\n",
    "        \n",
    "class func_allone(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #x is an input tensor, size N*C*H*W\n",
    "        #for cnn, functions are applied to each filter\n",
    "        N, C, H, W = x.size()\n",
    "        x = torch.mul(x.clone(), Variable(torch.ones(N, C, H, W), requires_grad=False).type(dtype))\n",
    "        return x\n",
    "\n",
    "class func_linear(nn.Module):\n",
    "    def __init__(self, k=1):\n",
    "        super(func_linear, self).__init__()\n",
    "        self.k = k\n",
    "    def channel_coeff(self, N, C, H, W):\n",
    "        coeff_list = list(map(lambda a: 1-(a/(C+1)), range(0,C)))\n",
    "        coeff_list = [[c] for c in coeff_list]\n",
    "        coeff = Variable(torch.Tensor(coeff_list)).type(dtype) #C\n",
    "        coeff_tensor = coeff.expand(C,H) #C*H\n",
    "        coeff_tensor = torch.stack([coeff_tensor]*W,1) #C*H*W\n",
    "        coeff_tensor = torch.stack(([coeff_tensor]*N)) #N*C*H*W\n",
    "        return coeff_tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size()\n",
    "        x = torch.mul(x.clone(), self.channel_coeff(N, C, H, W))\n",
    "        return x\n",
    "        \n",
    "class func_harmonic(nn.Module):\n",
    "    #perform element-wise multiplication to channels in x with coefficient k/n, n is channel index\n",
    "    def __init__(self, k=1):\n",
    "        super(func_harmonic, self).__init__()\n",
    "        self.k = k\n",
    "    def channel_coeff(self, N, C, H, W):\n",
    "        #C is channels, return a list with corresponding index: [k, k/2,...]\n",
    "        #returns a tensor with size N*C*H*W\n",
    "        coeff = list(map(lambda a: self.k/a, range(1,C+1)))\n",
    "        tensor_list = []\n",
    "        for c in coeff:\n",
    "            coeff_tensor = torch.ones(H, W)\n",
    "            coeff_tensor = torch.mul(coeff_tensor, c)\n",
    "            tensor_list.append(coeff_tensor)\n",
    "        ct = torch.stack(tensor_list, 0)\n",
    "        ct = torch.stack(([ct]*N))\n",
    "        return ct\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x is an input tensor, size N*C*H*W\n",
    "        #for cnn, functions are applied to each filter\n",
    "        N, C, H, W = x.size()\n",
    "        x = torch.mul(x.clone(), Variable(self.channel_coeff(N, C, H, W), requires_grad=False).type(dtype))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tesla_coef_idp_VGG_3branch(nn.Module):\n",
    "    def __init__(self, idp_layers, model=models.vgg16(pretrained=True).type(dtype), idp1=0.35, idp2=0.7, idp3=1):\n",
    "        #idp is 0~1, idp_layers is a set, specify which layer in features should apply idp\n",
    "        #now idp_layers is 3,6,8,11,13,15,18,20,22,25,27,29\n",
    "        super(tesla_coef_idp_VGG_3branch, self).__init__()\n",
    "        self.idp1 = idp1\n",
    "        self.idp2 = idp2\n",
    "        self.idp3 = idp3\n",
    "        self.idp_layers = idp_layers\n",
    "        self.features = nn.Sequential(*(self.new_features_list(model)))\n",
    "        self.classifier = nn.Sequential(nn.Linear(512, 512),\n",
    "                              nn.ReLU(inplace=True),\n",
    "                              nn.Dropout(0.5),\n",
    "                              nn.Linear(512, 10))\n",
    "        \n",
    "    \n",
    "    def new_features_list(self, model):\n",
    "        new_layers = []\n",
    "        #create from pre-trained resnet\n",
    "        for i, layer in enumerate(list(model.features.children())):\n",
    "            if i ==1:\n",
    "                new_layers.append(layer)\n",
    "                new_layers.append(func_linear())\n",
    "                new_layers.append(first_idp_tensor_3(self.idp1, self.idp2, self.idp3))\n",
    "            elif i not in self.idp_layers:\n",
    "                new_layers.append(layer)                \n",
    "            else:\n",
    "                new_layers.append(layer)\n",
    "                new_layers.append(func_linear())\n",
    "                new_layers.append(middle_idp_tensor_3(self.idp1, self.idp2, self.idp3))\n",
    "        new_layers.append(Flatten())\n",
    "        return new_layers        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        f = self.features(x)\n",
    "        NN, M = f.size()\n",
    "        N = int(NN/3)\n",
    "        o1 = f[:N, :]\n",
    "        o2 = f[N:2*N, :]\n",
    "        o3 = f[2*N:,:]\n",
    "        o1 = self.classifier(o1)\n",
    "        o2 = self.classifier(o2)\n",
    "        o3 = self.classifier(o3)\n",
    "        return o1, o2, o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# test the model by forward pass, output size\n",
    "idp_layers = {3,6,8,11,13,15,18,20,22,25,27,29}\n",
    "net = tesla_coef_idp_VGG_3branch(idp_layers, idp1=0.2, idp2=0.5, idp3=1).type(dtype)\n",
    "\n",
    "x = Variable(torch.randn(32, 3, 32, 32)).type(dtype)\n",
    "out1, out2, out3 = net(x)\n",
    "print(out1.size())\n",
    "print(out2.size())\n",
    "print(out3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_tesla_3(num_epoch, net, criterion, optimizer, alpha1=0, alpha2=0, alpha3=1, index=2):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "        running_loss1 = []\n",
    "        running_loss2 = []\n",
    "        running_correct1=[]\n",
    "        running_correct2=[]\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            correct = 0\n",
    "            net.train(True)\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs).type(dtype), Variable(labels).type(torch.cuda.LongTensor)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss1 = criterion(outputs[0], labels) #idp-low\n",
    "            loss2 = criterion(outputs[1], labels) #idp-mid\n",
    "            loss3 = criterion(outputs[2], labels) #idp-high\n",
    "            \n",
    "            loss = alpha1*loss1+alpha2*loss2+alpha3*loss3\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            # loss\n",
    "            running_loss1.append(loss.data[0])\n",
    "            # accuracy\n",
    "            _, predicted = torch.max(outputs[index].data, 1)\n",
    "            correct += (predicted == labels.data).sum()\n",
    "            correct = correct/labels.size(0)*100\n",
    "            running_correct1.append(correct)\n",
    "\n",
    "        for i, tdata in enumerate(valloader, 0):\n",
    "            test_correct = 0\n",
    "            net.train(False)\n",
    "            tinputs, tlabels = tdata\n",
    "            tinputs, tlabels = Variable(tinputs).type(dtype), Variable(tlabels).type(torch.cuda.LongTensor)\n",
    "            toutputs = net(tinputs)\n",
    "            tloss1 = criterion(toutputs[0], tlabels)\n",
    "            tloss2 = criterion(toutputs[1], tlabels)\n",
    "            tloss3 = criterion(toutputs[2], tlabels)\n",
    "            \n",
    "            tloss = alpha1*tloss1+alpha2*tloss2+alpha3*loss3\n",
    "            \n",
    "            running_loss2.append(tloss.data[0])\n",
    "            _, tpredicted = torch.max(toutputs[index].data, 1)\n",
    "            test_correct += (tpredicted == tlabels.data).sum()\n",
    "            test_correct = test_correct/tlabels.size(0)*100\n",
    "            running_correct2.append(test_correct)\n",
    "\n",
    "        train_loss.append(np.mean(running_loss1))\n",
    "        test_loss.append(np.mean(running_loss2))\n",
    "        train_acc.append(np.mean(running_correct1))\n",
    "        test_acc.append(np.mean(running_correct2))\n",
    "\n",
    "        #statistics\n",
    "        print('Epoch [%d/%d], Index=:%r, Train Loss:%.3f, Val Loss:%.3f, Train Accuracy:%.3f percent, Val Accuracy:%.3f percent' \n",
    "                    %(epoch+1, num_epoch, index, train_loss[-1], test_loss[-1], train_acc[-1], test_acc[-1]))\n",
    "        #save model every 10 epoch\n",
    "        if epoch!=0 and epoch%10 ==0:\n",
    "            file = 'saved_models/'+str(epoch)+'_epoch_tesla_linear_idp_model.pkl'\n",
    "            torch.save(net.state_dict(), file)\n",
    "        #early stopping\n",
    "        if epoch >= 3:\n",
    "            if (test_acc[-1] - test_acc[-2]) <=0 and (test_acc[-1] - test_acc[-3]) <= 0:\n",
    "                print('Early stopping')\n",
    "                return train_loss, test_loss, train_acc, test_acc, epoch\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return train_loss, test_loss, train_acc, test_acc, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Index=:1, Train Loss:2.303, Val Loss:2.302, Train Accuracy:10.067 percent, Val Accuracy:10.271 percent\n",
      "Epoch [2/15], Index=:1, Train Loss:2.057, Val Loss:1.784, Train Accuracy:17.800 percent, Val Accuracy:26.154 percent\n",
      "Epoch [3/15], Index=:1, Train Loss:1.662, Val Loss:1.445, Train Accuracy:31.634 percent, Val Accuracy:41.202 percent\n",
      "Epoch [4/15], Index=:1, Train Loss:1.281, Val Loss:1.079, Train Accuracy:49.822 percent, Val Accuracy:60.729 percent\n",
      "Epoch [5/15], Index=:1, Train Loss:0.966, Val Loss:0.906, Train Accuracy:65.287 percent, Val Accuracy:67.934 percent\n",
      "Epoch [6/15], Index=:1, Train Loss:0.807, Val Loss:0.725, Train Accuracy:71.707 percent, Val Accuracy:75.717 percent\n",
      "Epoch [7/15], Index=:1, Train Loss:0.695, Val Loss:0.646, Train Accuracy:76.264 percent, Val Accuracy:78.523 percent\n",
      "Epoch [8/15], Index=:1, Train Loss:0.608, Val Loss:0.665, Train Accuracy:79.681 percent, Val Accuracy:78.404 percent\n",
      "Epoch [9/15], Index=:1, Train Loss:0.532, Val Loss:0.650, Train Accuracy:82.172 percent, Val Accuracy:78.563 percent\n",
      "Epoch [10/15], Index=:1, Train Loss:0.477, Val Loss:0.619, Train Accuracy:84.299 percent, Val Accuracy:80.414 percent\n",
      "Epoch [11/15], Index=:1, Train Loss:0.425, Val Loss:0.630, Train Accuracy:85.950 percent, Val Accuracy:80.175 percent\n",
      "Epoch [12/15], Index=:1, Train Loss:0.373, Val Loss:0.570, Train Accuracy:87.798 percent, Val Accuracy:82.345 percent\n",
      "Epoch [13/15], Index=:1, Train Loss:0.336, Val Loss:0.609, Train Accuracy:88.886 percent, Val Accuracy:81.369 percent\n",
      "Epoch [14/15], Index=:1, Train Loss:0.300, Val Loss:0.613, Train Accuracy:89.963 percent, Val Accuracy:81.489 percent\n",
      "Epoch [15/15], Index=:1, Train Loss:0.264, Val Loss:0.609, Train Accuracy:91.207 percent, Val Accuracy:82.962 percent\n",
      "Finished Training\n",
      "Epoch [1/15], Index=:1, Train Loss:0.238, Val Loss:0.704, Train Accuracy:92.061 percent, Val Accuracy:81.290 percent\n",
      "Epoch [2/15], Index=:1, Train Loss:0.212, Val Loss:0.671, Train Accuracy:93.166 percent, Val Accuracy:82.285 percent\n",
      "Epoch [3/15], Index=:1, Train Loss:0.189, Val Loss:0.665, Train Accuracy:93.866 percent, Val Accuracy:81.907 percent\n",
      "Epoch [4/15], Index=:1, Train Loss:0.177, Val Loss:0.650, Train Accuracy:94.254 percent, Val Accuracy:82.842 percent\n"
     ]
    }
   ],
   "source": [
    "# define models, optimizers, randomized training\n",
    "idp_ranges = [0.2, 0.5, 1]\n",
    "all_train_loss = []\n",
    "all_test_loss = []\n",
    "all_train_acc = []\n",
    "all_test_acc = []\n",
    "\n",
    "idp_layers = {1,3,6,8,11,13,15,18,20,22,25,27,29}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net = tesla_coef_idp_VGG_3branch(idp_layers, idp1=0.2, idp2=0.5, idp3=1).type(dtype)\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "total_num_epoch = 50\n",
    "\n",
    "alpha = 0.5\n",
    "curr_alpha_list = [0, 0, 0]\n",
    "num_phases = 0\n",
    "\n",
    "while total_num_epoch > 0:\n",
    "    #sampling\n",
    "    sample_index = random.choice(range(len(idp_ranges))) #0,1,2\n",
    "    sample_idp = idp_ranges[sample_index] #idp value\n",
    "    #new alpha loss controller\n",
    "    new_alpha_list = [0, 0, 0]\n",
    "    new_alpha_list[sample_index] = 1-alpha\n",
    "    #together with prev alphas\n",
    "    if num_phases==0:\n",
    "        #start\n",
    "        alpha_input=[0, 0, 0]\n",
    "        alpha_input[sample_index]=1\n",
    "    else:    \n",
    "        alpha_input = [sum(x) for x in zip(curr_alpha_list, new_alpha_list)]\n",
    "    \n",
    "    train_loss, test_loss, train_acc, test_acc, used_epoch = train_tesla_3(num_epoch, net, criterion, optimizer, \n",
    "                                                                 alpha1=alpha_input[0], alpha2=alpha_input[1], \n",
    "                                                                 alpha3=alpha_input[2], index=sample_index)\n",
    "    curr_alpha_list = [x * alpha for x in alpha_input]\n",
    "\n",
    "    all_train_loss.extend(train_loss)\n",
    "    all_test_loss.extend(test_loss)\n",
    "    all_train_acc.extend(train_acc)\n",
    "    all_test_acc.extend(test_acc)\n",
    "    total_num_epoch = total_num_epoch-used_epoch\n",
    "    num_phases = num_phases+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "torch.save(net.state_dict(), 'saved_models/random_100_50_20_tesla_branch_linear_idp_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_losses(all_train_loss, all_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy(all_train_acc, all_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "net.load_state_dict(torch.load('saved_models/random_100_50_20_tesla_branch_linear_idp_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_acccuracy(testloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs1, outputs2, outputs3 = model.forward(Variable(images, volatile=True).type(dtype))\n",
    "        labels = Variable(labels, volatile=True).type(torch.cuda.LongTensor)\n",
    "        _, predicted = torch.max(outputs3.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "    acc = 100*correct/total\n",
    "    print('Accuracy of the network with IDP 100 on the test images: %d %%' % (acc))\n",
    "    return acc\n",
    "\n",
    "test_acccuracy(testloader, net.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idp_acc_history = []\n",
    "idp_harmonic_history = [0]*20\n",
    "\n",
    "idp_scale = list(map(lambda x: x/20,range(1,21)))\n",
    "print(idp_scale)\n",
    "for i in idp_scale:\n",
    "    net_inference = tesla_coef_idp_VGG_3branch(idp_layers, idp1=1, idp2=1, idp3=i).type(dtype)\n",
    "    net_inference.load_state_dict(torch.load('saved_models/100_50_20_tesla_branch_linear_idp_model.pkl'))\n",
    "    a = test_acccuracy(testloader, net_inference.eval())\n",
    "    idp_acc_history.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idp_acc_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
