{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import sampler\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.set_device(0)\n",
    "# specify dtype\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor\n",
    "print(torch.cuda.device_count())\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 4e-3\n",
    "momentum = 0.9\n",
    "num_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "data_path = '/home/put_data/frank840925/IDP/data'\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_path, \n",
    "                                        train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, \n",
    "                                          num_workers=4)\n",
    "\n",
    "valset = torchvision.datasets.CIFAR10(root=data_path, \n",
    "                                       train=False, download=True, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, sampler=ChunkSampler(5000,0), \n",
    "                                        num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_path, \n",
    "                                       train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, sampler=ChunkSampler(5000,5000),\n",
    "                                        num_workers=4)\n",
    "\n",
    "print(trainset.__len__())\n",
    "print(valset.__len__())\n",
    "print(testset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def plot_losses(loss_history1=None, loss_history2=None):\n",
    "    plt.clf()\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    if loss_history1:\n",
    "        ax1.plot(loss_history1, color=\"blue\", label=\"train\")\n",
    "    if loss_history2:\n",
    "        ax1.plot(loss_history2, color=\"green\", label=\"val\")\n",
    "    #ax2 = ax1.twinx()\n",
    "    #ax2.set_yscale('log')\n",
    "    plt.xlabel(\"epoch\") \n",
    "    plt.ylabel(\"loss\") \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(\"Cross-entropy loss\")\n",
    "    #plt.savefig('output_losses.png')\n",
    "\n",
    "def plot_accuracy(accuracy1=None, accuracy2=None):\n",
    "    plt.clf()\n",
    "    fig2 = plt.figure()\n",
    "    ax1 = fig2.add_subplot(111)\n",
    "    if accuracy1:\n",
    "        ax1.plot(accuracy1, color=\"red\", label=\"train\")\n",
    "    if accuracy2:\n",
    "        ax1.plot(accuracy2, color=\"black\", label=\"val\")\n",
    "    plt.xlabel(\"epoch\") \n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(\"Train/Val accuracy\") \n",
    "    #plt.savefig('accuracy.png')\n",
    "\n",
    "# get some random training images\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "#print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self-defined modules(layers)\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # read in N, C, H, W\n",
    "        N, C, H, W = x.size()\n",
    "        # flatten the C * H * W values into a single vector per image\n",
    "        return x.view(N, -1)  \n",
    "    \n",
    "class idp_tensor(nn.Module):\n",
    "    def __init__(self, idp):\n",
    "        super(idp_tensor, self).__init__()\n",
    "        self.idp = idp\n",
    "    def forward(self, c):\n",
    "        #input tensor c, size N*C*H*W, output with the same size, some channels zeroed according to idp\n",
    "        N, C, H, W = c.size()\n",
    "        non_zero_channel = int(C*(self.idp))\n",
    "        zero_channels = C-non_zero_channel\n",
    "        if zero_channels > 0:\n",
    "            #zeros = Variable(torch.zeros(N, zero_channels, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(zero_channels).view(zero_channels,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(zero_channels, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c = torch.cat([c[:, :non_zero_channel, :, :].clone(), zeros], 1).type(dtype)\n",
    "            #c[:, non_zero_channel:, :, :] = zeros\n",
    "            return c\n",
    "        else:\n",
    "            return c\n",
    "        \n",
    "class first_idp_tensor_3(nn.Module):\n",
    "    def __init__(self, idp1=0.35, idp2=0.7, idp3=1):\n",
    "        super(first_idp_tensor_3, self).__init__()\n",
    "        self.idp1 = idp1\n",
    "        self.idp2 = idp2\n",
    "        self.idp3 = idp3\n",
    "    def forward(self, c):\n",
    "        #input the first conv-Relu-Linear output, N*C*H*W, replicate and apply idp and concat in first dim (N)\n",
    "        N, C, H, W = c.size()\n",
    "        non_zero_channel_1 = int(C*(self.idp1))\n",
    "        non_zero_channel_2 = int(C*(self.idp2))\n",
    "        non_zero_channel_3 = int(C*(self.idp3))\n",
    "        if C-non_zero_channel_1 > 0:\n",
    "            #zeros = Variable(torch.zeros(N, C-non_zero_channel_1, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(C-non_zero_channel_1).view(C-non_zero_channel_1,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(C-non_zero_channel_1, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c1 = torch.cat([c[:, :non_zero_channel_1, :, :].clone(), zeros], 1).type(dtype)\n",
    "        else:\n",
    "            c1 = c\n",
    "        if C-non_zero_channel_2 > 0:\n",
    "            #zeros = Variable(torch.zeros(N, C-non_zero_channel_2, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(C-non_zero_channel_2).view(C-non_zero_channel_2,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(C-non_zero_channel_2, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c2 = torch.cat([c[:, :non_zero_channel_2, :, :].clone(), zeros], 1).type(dtype)\n",
    "        else:\n",
    "            c2 = c\n",
    "        if C-non_zero_channel_3 > 0:\n",
    "            #zeros = Variable(torch.zeros(N, C-non_zero_channel_3, H, W)).type(dtype)\n",
    "            zeros = Variable(torch.zeros(C-non_zero_channel_3).view(C-non_zero_channel_3,1)).type(dtype) #C\n",
    "            zeros = zeros.expand(C-non_zero_channel_3, H) #C*H\n",
    "            zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "            zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "            c3 = torch.cat([c[:, :non_zero_channel_3, :, :].clone(), zeros], 1).type(dtype)\n",
    "        else:\n",
    "            c3 = c\n",
    "        out = torch.cat([c1, c2, c3], 0)\n",
    "        return out\n",
    "        \n",
    "class middle_idp_tensor_3(nn.Module):\n",
    "    def __init__(self, idp1=0.35, idp2=0.7, idp3=1):\n",
    "        super(middle_idp_tensor_3, self).__init__()\n",
    "        self.idp1 = idp1\n",
    "        self.idp2 = idp2\n",
    "        self.idp3 = idp3\n",
    "    def forward(self, c):\n",
    "        #input a middle conv-Relu-Linear output, (3*N)*C*H*W, apply IDP1, IDP2, IDP3 to each\n",
    "        NN, C, H, W = c.size()\n",
    "        if NN>=3:\n",
    "            N = int(NN/3)\n",
    "            non_zero_channel_1 = int(C*(self.idp1))\n",
    "            non_zero_channel_2 = int(C*(self.idp2))\n",
    "            non_zero_channel_3 = int(C*(self.idp3))\n",
    "            c1 = c[:N,:,:,:]\n",
    "            c2 = c[N:2*N,:,:,:]\n",
    "            c3 = c[2*N:,:,:,:]\n",
    "            if C-non_zero_channel_1 > 0:\n",
    "                #zeros = Variable(torch.zeros(N, C-non_zero_channel_1, H, W)).type(dtype)\n",
    "                zeros = Variable(torch.zeros(C-non_zero_channel_1).view(C-non_zero_channel_1,1)).type(dtype) #C\n",
    "                zeros = zeros.expand(C-non_zero_channel_1, H) #C*H\n",
    "                zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "                zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "                c1 = torch.cat([c1[:, :non_zero_channel_1, :, :].clone(), zeros], 1).type(dtype)\n",
    "            else:\n",
    "                c1 = c1\n",
    "            if C-non_zero_channel_2 > 0:\n",
    "                #zeros = Variable(torch.zeros(N, C-non_zero_channel_2, H, W)).type(dtype)\n",
    "                zeros = Variable(torch.zeros(C-non_zero_channel_2).view(C-non_zero_channel_2,1)).type(dtype) #C\n",
    "                zeros = zeros.expand(C-non_zero_channel_2, H) #C*H\n",
    "                zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "                zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "                c2 = torch.cat([c2[:, :non_zero_channel_2, :, :].clone(), zeros], 1).type(dtype)\n",
    "            else:\n",
    "                c2 = c2\n",
    "            if C-non_zero_channel_3 > 0:\n",
    "                #zeros = Variable(torch.zeros(N, C-non_zero_channel_3, H, W)).type(dtype)\n",
    "                zeros = Variable(torch.zeros(C-non_zero_channel_3).view(C-non_zero_channel_3,1)).type(dtype) #C\n",
    "                zeros = zeros.expand(C-non_zero_channel_3, H) #C*H\n",
    "                zeros = torch.stack([zeros]*W,1) #C*H*W\n",
    "                zeros = torch.stack([zeros]*N) #N*C*H*W\n",
    "                c3 = torch.cat([c3[:, :non_zero_channel_3, :, :].clone(), zeros], 1).type(dtype)\n",
    "            else:\n",
    "                c3 = c3\n",
    "            out = torch.cat([c1, c2, c3],0)\n",
    "            return out\n",
    "        else:\n",
    "            return c\n",
    "        \n",
    "class func_allone(nn.Module):\n",
    "    def forward(self, x):\n",
    "        #x is an input tensor, size N*C*H*W\n",
    "        #for cnn, functions are applied to each filter\n",
    "        N, C, H, W = x.size()\n",
    "        x = torch.mul(x.clone(), Variable(torch.ones(N, C, H, W), requires_grad=False).type(dtype))\n",
    "        return x\n",
    "    \n",
    "class func_allone_trainable(nn.Module):\n",
    "    def channel_coeff(self, N, C, H, W):\n",
    "        coeff_tensor = nn.Parameter(torch.ones(C).view(C, 1), requires_grad=True).type(dtype) #C\n",
    "        coeff_tensor = coeff_tensor.expand(C, H) #C*H\n",
    "        coeff_tensor = torch.stack([coeff_tensor]*W,1) #C*H*W\n",
    "        coeff_tensor = torch.stack(([coeff_tensor]*N)) #N*C*H*W\n",
    "        return coeff_tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size()\n",
    "        x = torch.mul(x.clone(), self.channel_coeff(N, C, H, W))\n",
    "        return x\n",
    "\n",
    "class func_linear(nn.Module):\n",
    "    def __init__(self, k=1):\n",
    "        super(func_linear, self).__init__()\n",
    "        self.k = k\n",
    "    def channel_coeff(self, N, C, H, W):\n",
    "        coeff_list = list(map(lambda a: 1-(a/(C+1)), range(0,C)))\n",
    "        coeff_list = [[c] for c in coeff_list]\n",
    "        coeff = Variable(torch.Tensor(coeff_list)).type(dtype) #C\n",
    "        coeff_tensor = coeff.expand(C,H) #C*H\n",
    "        coeff_tensor = torch.stack([coeff_tensor]*W,1) #C*H*W\n",
    "        coeff_tensor = torch.stack(([coeff_tensor]*N)) #N*C*H*W\n",
    "        return coeff_tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size()\n",
    "        x = torch.mul(x.clone(), self.channel_coeff(N, C, H, W))\n",
    "        return x\n",
    "        \n",
    "class func_harmonic(nn.Module):\n",
    "    #perform element-wise multiplication to channels in x with coefficient k/n, n is channel index\n",
    "    def __init__(self, k=1):\n",
    "        super(func_harmonic, self).__init__()\n",
    "        self.k = k\n",
    "    def channel_coeff(self, N, C, H, W):\n",
    "        #C is channels, return a list with corresponding index: [k, k/2,...]\n",
    "        #returns a tensor with size N*C*H*W\n",
    "        coeff = list(map(lambda a: self.k/a, range(1,C+1)))\n",
    "        tensor_list = []\n",
    "        for c in coeff:\n",
    "            coeff_tensor = torch.ones(H, W)\n",
    "            coeff_tensor = torch.mul(coeff_tensor, c)\n",
    "            tensor_list.append(coeff_tensor)\n",
    "        ct = torch.stack(tensor_list, 0)\n",
    "        ct = torch.stack(([ct]*N))\n",
    "        return ct\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x is an input tensor, size N*C*H*W\n",
    "        #for cnn, functions are applied to each filter\n",
    "        N, C, H, W = x.size()\n",
    "        x = torch.mul(x.clone(), Variable(self.channel_coeff(N, C, H, W), requires_grad=False).type(dtype))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tesla_coef_idp_VGG_3branch(nn.Module):\n",
    "    def __init__(self, idp_layers, model=models.vgg16(pretrained=True).type(dtype), idp1=0.35, idp2=0.7, idp3=1):\n",
    "        #idp is 0~1, idp_layers is a set, specify which layer in features should apply idp\n",
    "        #now idp_layers is 3,6,8,11,13,15,18,20,22,25,27,29\n",
    "        super(tesla_coef_idp_VGG_3branch, self).__init__()\n",
    "        self.idp1 = idp1\n",
    "        self.idp2 = idp2\n",
    "        self.idp3 = idp3\n",
    "        self.idp_layers = idp_layers\n",
    "        self.features = nn.Sequential(*(self.new_features_list(model)))\n",
    "        print(len(list(self.features.parameters())))\n",
    "        #self.features = self.new_features_list(model)\n",
    "        self.classifier = nn.Sequential(nn.Linear(512, 512),\n",
    "                              nn.ReLU(inplace=True),\n",
    "                              nn.Dropout(0.5),\n",
    "                              nn.Linear(512, 10))\n",
    "        print(len(list(self.classifier.parameters())))\n",
    "    \n",
    "    def new_features_list(self, model):\n",
    "        new_layers = nn.ModuleList()\n",
    "        #create from pre-trained resnet\n",
    "        for i, layer in enumerate(list(model.features.children())):\n",
    "            if i ==1:\n",
    "                new_layers.append(layer)\n",
    "                new_layers.append(func_allone_trainable())\n",
    "                new_layers.append(first_idp_tensor_3(self.idp1, self.idp2, self.idp3))\n",
    "            elif i not in self.idp_layers:\n",
    "                new_layers.append(layer)                \n",
    "            else:\n",
    "                new_layers.append(layer)\n",
    "                new_layers.append(func_allone_trainable())\n",
    "                new_layers.append(middle_idp_tensor_3(self.idp1, self.idp2, self.idp3))\n",
    "        new_layers.append(Flatten())\n",
    "        return new_layers        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        f = self.features(x)\n",
    "        NN, M = f.size()\n",
    "        N = int(NN/3)\n",
    "        o1 = f[:N, :]\n",
    "        o2 = f[N:2*N, :]\n",
    "        o3 = f[2*N:,:]\n",
    "        o1 = self.classifier(o1)\n",
    "        o2 = self.classifier(o2)\n",
    "        o3 = self.classifier(o3)\n",
    "        return o1, o2, o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "4\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# test the model by forward pass, output size\n",
    "idp_layers = {3,6,8,11,13,15,18,20,22,25,27,29}\n",
    "net = tesla_coef_idp_VGG_3branch(idp_layers, idp1=0.1, idp2=0.35, idp3=1).type(dtype)\n",
    "\n",
    "x = Variable(torch.randn(32, 3, 32, 32)).type(dtype)\n",
    "out1, out2, out3 = net(x)\n",
    "print(out1.size())\n",
    "print(out2.size())\n",
    "print(out3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> ('', tesla_coef_idp_VGG_3branch (\n",
      "  (features): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU (inplace)\n",
      "    (2): func_allone_trainable (\n",
      "    )\n",
      "    (3): first_idp_tensor_3 (\n",
      "    )\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU (inplace)\n",
      "    (6): func_allone_trainable (\n",
      "    )\n",
      "    (7): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (8): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU (inplace)\n",
      "    (11): func_allone_trainable (\n",
      "    )\n",
      "    (12): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU (inplace)\n",
      "    (15): func_allone_trainable (\n",
      "    )\n",
      "    (16): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (17): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU (inplace)\n",
      "    (20): func_allone_trainable (\n",
      "    )\n",
      "    (21): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): ReLU (inplace)\n",
      "    (24): func_allone_trainable (\n",
      "    )\n",
      "    (25): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (26): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU (inplace)\n",
      "    (28): func_allone_trainable (\n",
      "    )\n",
      "    (29): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (31): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (32): ReLU (inplace)\n",
      "    (33): func_allone_trainable (\n",
      "    )\n",
      "    (34): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (35): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (36): ReLU (inplace)\n",
      "    (37): func_allone_trainable (\n",
      "    )\n",
      "    (38): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (40): ReLU (inplace)\n",
      "    (41): func_allone_trainable (\n",
      "    )\n",
      "    (42): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (43): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (44): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (45): ReLU (inplace)\n",
      "    (46): func_allone_trainable (\n",
      "    )\n",
      "    (47): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (48): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (49): ReLU (inplace)\n",
      "    (50): func_allone_trainable (\n",
      "    )\n",
      "    (51): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (52): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (53): ReLU (inplace)\n",
      "    (54): func_allone_trainable (\n",
      "    )\n",
      "    (55): middle_idp_tensor_3 (\n",
      "    )\n",
      "    (56): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (57): Flatten (\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential (\n",
      "    (0): Linear (512 -> 512)\n",
      "    (1): ReLU (inplace)\n",
      "    (2): Dropout (p = 0.5)\n",
      "    (3): Linear (512 -> 10)\n",
      "  )\n",
      "))\n",
      "1 -> ('features', Sequential (\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU (inplace)\n",
      "  (2): func_allone_trainable (\n",
      "  )\n",
      "  (3): first_idp_tensor_3 (\n",
      "  )\n",
      "  (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): ReLU (inplace)\n",
      "  (6): func_allone_trainable (\n",
      "  )\n",
      "  (7): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (8): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (10): ReLU (inplace)\n",
      "  (11): func_allone_trainable (\n",
      "  )\n",
      "  (12): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU (inplace)\n",
      "  (15): func_allone_trainable (\n",
      "  )\n",
      "  (16): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (17): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): ReLU (inplace)\n",
      "  (20): func_allone_trainable (\n",
      "  )\n",
      "  (21): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (23): ReLU (inplace)\n",
      "  (24): func_allone_trainable (\n",
      "  )\n",
      "  (25): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (26): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU (inplace)\n",
      "  (28): func_allone_trainable (\n",
      "  )\n",
      "  (29): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (30): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (31): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (32): ReLU (inplace)\n",
      "  (33): func_allone_trainable (\n",
      "  )\n",
      "  (34): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (35): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (36): ReLU (inplace)\n",
      "  (37): func_allone_trainable (\n",
      "  )\n",
      "  (38): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (39): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (40): ReLU (inplace)\n",
      "  (41): func_allone_trainable (\n",
      "  )\n",
      "  (42): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (43): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (44): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (45): ReLU (inplace)\n",
      "  (46): func_allone_trainable (\n",
      "  )\n",
      "  (47): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (48): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (49): ReLU (inplace)\n",
      "  (50): func_allone_trainable (\n",
      "  )\n",
      "  (51): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (52): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (53): ReLU (inplace)\n",
      "  (54): func_allone_trainable (\n",
      "  )\n",
      "  (55): middle_idp_tensor_3 (\n",
      "  )\n",
      "  (56): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (57): Flatten (\n",
      "  )\n",
      "))\n",
      "2 -> ('features.0', Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "3 -> ('features.1', ReLU (inplace))\n",
      "4 -> ('features.2', func_allone_trainable (\n",
      "))\n",
      "5 -> ('features.3', first_idp_tensor_3 (\n",
      "))\n",
      "6 -> ('features.4', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "7 -> ('features.5', ReLU (inplace))\n",
      "8 -> ('features.6', func_allone_trainable (\n",
      "))\n",
      "9 -> ('features.7', middle_idp_tensor_3 (\n",
      "))\n",
      "10 -> ('features.8', MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)))\n",
      "11 -> ('features.9', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "12 -> ('features.10', ReLU (inplace))\n",
      "13 -> ('features.11', func_allone_trainable (\n",
      "))\n",
      "14 -> ('features.12', middle_idp_tensor_3 (\n",
      "))\n",
      "15 -> ('features.13', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "16 -> ('features.14', ReLU (inplace))\n",
      "17 -> ('features.15', func_allone_trainable (\n",
      "))\n",
      "18 -> ('features.16', middle_idp_tensor_3 (\n",
      "))\n",
      "19 -> ('features.17', MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)))\n",
      "20 -> ('features.18', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "21 -> ('features.19', ReLU (inplace))\n",
      "22 -> ('features.20', func_allone_trainable (\n",
      "))\n",
      "23 -> ('features.21', middle_idp_tensor_3 (\n",
      "))\n",
      "24 -> ('features.22', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "25 -> ('features.23', ReLU (inplace))\n",
      "26 -> ('features.24', func_allone_trainable (\n",
      "))\n",
      "27 -> ('features.25', middle_idp_tensor_3 (\n",
      "))\n",
      "28 -> ('features.26', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "29 -> ('features.27', ReLU (inplace))\n",
      "30 -> ('features.28', func_allone_trainable (\n",
      "))\n",
      "31 -> ('features.29', middle_idp_tensor_3 (\n",
      "))\n",
      "32 -> ('features.30', MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)))\n",
      "33 -> ('features.31', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "34 -> ('features.32', ReLU (inplace))\n",
      "35 -> ('features.33', func_allone_trainable (\n",
      "))\n",
      "36 -> ('features.34', middle_idp_tensor_3 (\n",
      "))\n",
      "37 -> ('features.35', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "38 -> ('features.36', ReLU (inplace))\n",
      "39 -> ('features.37', func_allone_trainable (\n",
      "))\n",
      "40 -> ('features.38', middle_idp_tensor_3 (\n",
      "))\n",
      "41 -> ('features.39', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "42 -> ('features.40', ReLU (inplace))\n",
      "43 -> ('features.41', func_allone_trainable (\n",
      "))\n",
      "44 -> ('features.42', middle_idp_tensor_3 (\n",
      "))\n",
      "45 -> ('features.43', MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)))\n",
      "46 -> ('features.44', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "47 -> ('features.45', ReLU (inplace))\n",
      "48 -> ('features.46', func_allone_trainable (\n",
      "))\n",
      "49 -> ('features.47', middle_idp_tensor_3 (\n",
      "))\n",
      "50 -> ('features.48', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "51 -> ('features.49', ReLU (inplace))\n",
      "52 -> ('features.50', func_allone_trainable (\n",
      "))\n",
      "53 -> ('features.51', middle_idp_tensor_3 (\n",
      "))\n",
      "54 -> ('features.52', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))\n",
      "55 -> ('features.53', ReLU (inplace))\n",
      "56 -> ('features.54', func_allone_trainable (\n",
      "))\n",
      "57 -> ('features.55', middle_idp_tensor_3 (\n",
      "))\n",
      "58 -> ('features.56', MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)))\n",
      "59 -> ('features.57', Flatten (\n",
      "))\n",
      "60 -> ('classifier', Sequential (\n",
      "  (0): Linear (512 -> 512)\n",
      "  (1): ReLU (inplace)\n",
      "  (2): Dropout (p = 0.5)\n",
      "  (3): Linear (512 -> 10)\n",
      "))\n",
      "61 -> ('classifier.0', Linear (512 -> 512))\n",
      "62 -> ('classifier.1', ReLU (inplace))\n",
      "63 -> ('classifier.2', Dropout (p = 0.5))\n",
      "64 -> ('classifier.3', Linear (512 -> 10))\n"
     ]
    }
   ],
   "source": [
    "for idx, m in enumerate(net.named_modules()):\n",
    "     print(idx, '->', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([64, 3, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([64])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([64])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([128, 64, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([128])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([128, 128, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([128])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([256, 128, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([256])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([256, 256, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([256])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([256, 256, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([256])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512, 256, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512, 512, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512, 512, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512, 512, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512, 512, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512, 512, 3, 3])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512, 512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([10, 512])\n",
      "<class 'torch.cuda.FloatTensor'> torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(len(list(net.parameters())))\n",
    "for param in net.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
